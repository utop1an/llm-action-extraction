from helpers import ten_fold_split_ind, index2data, load_pkl
import numpy as np
from copy import deepcopy
import os

def build_dict(domain):
    """
    Buiild part-of-speech dictionary
    """
    pos_dict = {'PAD': 0}
    for domain in ['cooking', 'win2k', 'wikihow']:
        sent_data = load_pkl(os.path.join(os.path.dirname(__file__), '../../data/easdrl', '%s_labeled_text_data.pkl' % domain))
        for sents in sent_data:
            print(sents)
            for sent in sents:
                for word, pos in sent:
                    if pos not in pos_dict:
                        pos_dict[pos] = len(pos_dict)

    print('len(pos_dict): %d' % len(pos_dict))

def read_act_texts(domain, pos_dict):
    """
    Read data for action name extractor
    PS: pos_data is generated by the function ``pos_tagging" in utils.py
    """

    text_data = load_pkl(os.path.join('../../data', '%s_labeled_text_data.pkl' % domain))
    pos_data = load_pkl(os.path.join('../../data', '%s_dependency.pkl' % domain))
    act_texts = []
    #ipdb.set_trace()
    for i in range(len(text_data)):
        act_text = {}
        act_text['tokens'] = text_data[i]['words']
        act_text['sents'] = text_data[i]['sents']
        act_text['acts'] = text_data[i]['acts']
        act_text['sent_acts'] = text_data[i]['sent_acts']
        act_text['word2sent'] = text_data[i]['word2sent']
        act_text['tags'] = np.ones(len(text_data[i]['words']), dtype=np.int32)
        act_text['act2related'] = {}
        for acts in text_data[i]['acts']:
            act_text['act2related'][acts['act_idx']] = acts['related_acts']
            act_text['tags'][acts['act_idx']] = acts['act_type'] + 1 # 2, 3, 4
        act_text['pos'] = []
        for sent in pos_data[i]:
            for word, pos in sent:
                act_text['pos'].append(pos_dict[pos])

        create_matrix(act_text)
        act_texts.append(act_text)
    act_indices = ten_fold_split_ind(len(act_texts), k_fold_indices, k_fold)
    act_data = index2data(act_indices, act_texts)
    return act_data


def read_arg_sents(domain, pos_dict, k_fold_indices, k_fold):
    """
    Read data for action argument extractor
    PS: pos_data is generated by the function ``pos_tagging" in utils.py
    """

    indata = load_pkl(os.path.join("../../data", 'refined_%s_data.pkl'%domain))[-1]
    pos_data = load_pkl(os.path.join("../../data", '%s_arg_pos.pkl' % domain))
    arg_sents = []
    # ipdb.set_trace()
    for i in range(len(indata)):
        for j in range(len(indata[i])):
            if len(indata[i][j]) == 0:
                continue
            # -1 obj_ind refer to UNK
            words = indata[i][j]['last_sent'] + indata[i][j]['this_sent'] + ['UNK'] 
            pos = [self.pos_dict[p] for w, p in pos_data[i][j][0] + pos_data[i][j][1]] + [0]
            if len(words) != len(words):
                ipdb.set_trace()
                print('len(words) != len(words)')
            sent_len = len(words)
            act_inds = [a['act_idx'] for a in indata[i][j]['acts'] if a['act_idx'] < self.num_words]
            for k in range(len(indata[i][j]['acts'])):
                act_ind = indata[i][j]['acts'][k]['act_idx']
                obj_inds = indata[i][j]['acts'][k]['obj_idxs']
                arg_sent = {}
                arg_tags = np.ones(sent_len, dtype=np.int32)
                if len(obj_inds[1]) == 0:
                    arg_tags[obj_inds[0]] = 2 # essential objects
                else:
                    arg_tags[obj_inds[0]] = 4 # exclusive objects
                    arg_tags[obj_inds[1]] = 4 # exclusive objects
                # generate distance representation
                position = np.zeros(sent_len, dtype=np.int32)
                position.fill(act_ind)
                distance = np.abs(np.arange(sent_len) - position)
                
                arg_sent['tokens'] = words
                arg_sent['tags'] = arg_tags
                arg_sent['pos'] = deepcopy(pos)
                arg_sent['act_ind'] = act_ind
                arg_sent['distance'] = distance
                arg_sent['act_inds'] = act_inds
                arg_sent['obj_inds'] = obj_inds
                self.create_matrix(arg_sent)
                arg_sents.append(arg_sent)
    # get k-fold split data
    arg_indices = ten_fold_split_ind(len(arg_sents), k_fold_indices, k_fold)
    arg_data = index2data(arg_indices, arg_sents)
    return arg_data

def create_matrix(self, sentence):
    """
    Create state representation
    """
    # get word vectors from pre-trained word2vec model
    sent_vec = []
    for w in sentence['tokens']:
        if w in self.word2vec.vocab:
            sent_vec.append(self.word2vec[w])
        else:
            sent_vec.append(np.zeros(self.word_dim))

    # padding
    sent_vec = np.array(sent_vec)
    pad_len = self.num_words - len(sent_vec)
    if self.agent_mode == 'act':
        if pad_len > 0:
            sent_vec = np.concatenate((sent_vec, np.zeros([pad_len, self.word_dim])))
            sentence['tags'] = np.concatenate((np.array(sentence['tags']), np.ones(pad_len, dtype=np.int32)))
            sentence['pos'].extend([0] * pad_len)
        else:
            sent_vec = sent_vec[: self.num_words]
            sentence['pos'] = sentence['pos'][: self.num_words]
            sentence['tokens'] = sentence['tokens'][: self.num_words]
            sentence['tags'] = np.array(sentence['tags'])[: self.num_words]

    else: # self.agent_mode == 'arg':
        distance = np.zeros([self.num_words, self.dis_dim])
        act_vec = sent_vec[sentence['act_ind']]  # word vector of the input action 
        # compute dot attention between the input action and its context 
        # attention = np.sum(sent_vec * act_vec, axis=1)  
        # attention = np.exp(attention)
        # attention /= sum(attention)
        if pad_len > 0:
            sent_vec = np.concatenate((sent_vec, np.zeros([pad_len, self.word_dim])))
            sentence['tags'] = np.concatenate((np.array(sentence['tags']), np.ones(pad_len, dtype=np.int32)))
            sentence['pos'].extend([0] * pad_len)
            # attention = np.concatenate((attention, np.zeros(pad_len)))
            for d in range(len(sentence['distance'])):
                distance[d] = sentence['distance'][d]
        else:
            sent_vec = sent_vec[: self.num_words]
            sentence['tokens'] = sentence['tokens'][: self.num_words]
            sentence['tags'] = np.array(sentence['tags'])[: self.num_words]
            sentence['pos'] = sentence['pos'][: self.num_words]
            # attention = attention[: self.num_words]
            for d in range(self.num_words):
                distance[d] = sentence['distance'][d]
        # ipdb.set_trace()
        # if self.use_act_att: # apply attention to word embedding
        #     sent_vec = attention.reshape(-1, 1) * sent_vec
        sent_vec = np.concatenate((sent_vec, distance), axis=1)

    sentence['sent_vec'] = sent_vec
    sentence['pos'] = np.array(sentence['pos'])[:, np.newaxis]
    sentence['tags'].shape = (self.num_words, 1)


if __name__ == "__main__":
    pos_dict = build_dict('cooking')